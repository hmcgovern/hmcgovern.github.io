---
title: "Your Large Language Models Are Leaving Fingerprints"
collection: publications
permalink: /publication/2015-10-01-paper-title-number-3
excerpt: 'It has been shown that fine-tuned transformers  and other supervised detectors are effective for distinguishing between human and machine-generated texts (in non-adversarial settings), 
but we find that even simple classifiers on top of n-gram and part-of-speech features can achieve very robust performance on both in- and out-of-domain data.
To understand how this is possible, we analyze machine-generated output text in four datasets,
finding that LLMs possess unique _fingerprints_ which manifest as slight differences in the frequency of certain lexical and morphosyntactic features.
We show how to visualize such fingerprints, describe how they can be used to detect machine-generated text and find that they are even robust across text domains.
We find that fingerprints are often persistent across models in the same model family (e.g. 13B parameter LLaMA's fingerprint is similar to that of 65B parameter LLaMA) 
and that while a detector trained on text from one model can easily recognize text generated by a model in the same family, it struggles to detect text generated by an unrelated model.'
date: 2024-05-22
#venue: '1st Annual Workshop on Machine Learning for Ancient Languages'
paperurl: 'https://arxiv.org/abs/2405.14057'
#citation: 'Jahr, Wiebke. McGovern, Hope. Danzl, Johann Georg (2020). &quot;Paper Title Number 3.&quot; <i>Journal 1</i>. 1(3).'
---


<!-- Recommended citation: Your Name, You. (2015). "Paper Title Number 3." <i>Focus on Microscopy</i>. 1(3). -->